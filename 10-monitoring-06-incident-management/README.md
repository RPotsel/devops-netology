# 10.06. Инцидент-менеджмент - Роман Поцелуев

## Задание 

Составьте постмортем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

---

## Краткое описание инцидента

C 21 октября 22:52 UTC по 22 октября 23:03 UTC в результате потери сетевого соединения между центрами обработки данных и последующих проблем в работе кластера БД, пользователи сайта не могли пользоваться сервисами веб-хуков и сборкой GitHub Page, предоставляемая сайтам информация была не актуальна.

## Предшествующие события

Работы по замене сетевого оборудования.

## Причина инцидента

Некорректная настройка согласованности конфигурации Orchestrator с работой на уровне приложения.

## Воздействие

В течение суток не работали сервисы веб-хуков и сборки GitHub Page, сайт предоставлял пользователям не актуальную информацию.

## Обнаружение

Внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в системах.

## Реакция

Устранение инцидента командой инженеров заняло сутки.

## Восстановление

Восстановление из резервных копий всех затронутых кластеров MySQL, с последующей синхронизацией реплик и накатом накопившихся изменений.

## Таймлайн

- **2018 октябрь 21 22:52 UTC** - потеря связи между серверами кластера БД MySQL на 43 секунды, в течении которого произошел переход первичных сервисов БД на реплики, в результате некорректной настройки согласованности конфигурации Orchestrator с работой на уровне приложения после восстановления соединения не получилось выполнить репликацию данных между узлами кластера.
- **2018 октябрь 21 22:54 UTC** - внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в системах.
- **2018 октябрь 21 23:07 UTC** - команда заблокировала внутренние инструменты развертывания для предотвращения внесения изменений в систему.
- **2018 октябрь 21 23:09 UTC** - команда опубликовала жёлтый статус сайта и система эскалации переводит запрос в инцидент и направляет предупреждение координатору инцидентов.
- **2018 октябрь 21 23:11 UTC** - координатор присоединился к команде и изменил статус на красный.
- **2018 октябрь 21 23:13 UTC** - к команде присоединились инженеры из группы разработки баз данных.
- **2018 октябрь 21 23:19 UTC** - команда остановила работу веб-хуков и сборку GitHub Page, тем самым ограничив использование внешних сервисов.
- **2018 октябрь 22 00:05 UTC** - команда начала разработку плана по восстановлению кластера БД.
- **2018 октябрь 22 00:41 UTC** - инициирован процесс восстановления из резервных копий всех затронутых кластеров MySQL.
- **2018 октябрь 22 06:51 UTC** - кластеров завершили восстановление из резервных копий и начали репликацию новых данных. Другие более крупные кластеры баз данных все еще восстанавливались.
- **2018 октябрь 22 07:46 UTC** - команда опубликовала сообщение в блоге, чтобы предоставить больше информации пользователям.
- **2018 октябрь 22 11:12 UTC** - восстановился основной кластер БД, но множество реплик БД продолжали отставать от основной на несколько часов, это приводило к тому что, пользователи видели несогласованные данные при взаимодействии со службами сайта.
- **2018 октябрь 22 13:15 UTC** - пик нагрузки трафика на сайт, принято решение развертывание дополнительных реплик на чтение.
- **2018 октябрь 22 16:24 UTC** - синхронизация реплик завершилась, начался возврат к исходной топологии.
- **2018 октябрь 22 16:45 UTC** - начался процесс обработки накопившихся событий.
- **2018 октябрь 22 23:03 UTC** - завершение обработки накопившихся событий, восстановление работы всех служб сайта.

## Последующие действия

- Внесение запросов не попавших в систему в процессе восстановления
- Настройка конфигурации Orchestrator для управления топологиями кластеров MySQL и автоматического аварийного переключения, чтобы предотвратить передачу primary роли между регионами
- Переход на новый механизм отчетов, информирующий о состоянии каждой службы
- Разработка механизмов резервирования N+1 на уровне объекта с возможностью отказа одного центра обработки данных без воздействия на пользователя
- Введение практики проверки сценариев сбоев и хаос-инжиниринга
